{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to forecast inventory demand based on historical sales data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy is RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data \n",
    "The size of the training data is quite large (~4 GB). Large datasets require significant amount of memory to process. Instead, we will sample the data randomly for our initial data analysis and visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "Time to load:  0.296472787857 sec\n",
      "\n",
      "            week_num  sales_depot_id  sales_chan_id       route_id  \\\n",
      "count  150000.000000   150000.000000  150000.000000  150000.000000   \n",
      "mean        5.982820     2785.281267       1.378807    2116.544753   \n",
      "std         2.027124     4660.731926       1.454210    1486.426860   \n",
      "min         3.000000     1110.000000       1.000000       1.000000   \n",
      "25%         4.000000     1312.000000       1.000000    1162.000000   \n",
      "50%         6.000000     1614.000000       1.000000    1287.000000   \n",
      "75%         8.000000     2038.000000       1.000000    2803.000000   \n",
      "max         9.000000    25759.000000      11.000000    9892.000000   \n",
      "\n",
      "          client_id        prod_id  saleunit_curr_wk  saleamt_curr_wk  \\\n",
      "count  1.500000e+05  150000.000000     150000.000000    150000.000000   \n",
      "mean   1.808100e+06   20917.492180          7.290980        68.851745   \n",
      "std    1.839784e+06   18654.697725         21.046499       307.624295   \n",
      "min    1.050000e+02      72.000000          0.000000         0.000000   \n",
      "25%    3.597660e+05    1242.000000          2.000000        16.760000   \n",
      "50%    1.200138e+06   30549.000000          3.000000        30.000000   \n",
      "75%    2.376863e+06   37427.000000          7.000000        56.100000   \n",
      "max    1.035181e+07   49994.000000       2108.000000     38620.960000   \n",
      "\n",
      "       retunit_next_week  retamt_next_wk  y_pred_demand  \n",
      "count      150000.000000   150000.000000  150000.000000  \n",
      "mean            0.123680        1.205767       7.206833  \n",
      "std             1.646204       17.002674      20.899182  \n",
      "min             0.000000        0.000000       0.000000  \n",
      "25%             0.000000        0.000000       2.000000  \n",
      "50%             0.000000        0.000000       3.000000  \n",
      "75%             0.000000        0.000000       6.000000  \n",
      "max           193.000000     2696.980000    2108.000000  \n",
      "*********\n",
      "        week_num  sales_depot_id  sales_chan_id  route_id  client_id  prod_id\n",
      "407495       3.0          1119.0            1.0    1260.0  4655180.0  41843.0\n",
      "998128       3.0          1130.0            1.0    1210.0   937277.0  35651.0\n",
      "435331       3.0          1119.0            1.0    1481.0  1883488.0   1216.0\n",
      "570645       3.0          1121.0            1.0    1639.0  2195156.0    323.0\n",
      "475547       3.0          1120.0            1.0    1476.0   170945.0   1250.0\n",
      "862766       3.0          1126.0            1.0    1219.0  4570976.0   1284.0\n",
      "425898       3.0          1119.0            1.0    1468.0    66840.0   1242.0\n",
      "627653       3.0          1122.0            1.0    1454.0  4187031.0   1278.0\n",
      "899892       3.0          1126.0            1.0    1439.0   433880.0  32819.0\n",
      "246230       3.0          1117.0            1.0    1048.0    64516.0   1182.0\n",
      "210464       3.0          1116.0            1.0    1609.0    16743.0   2505.0\n",
      "58040        3.0          1111.0            1.0    1641.0  4490132.0  30415.0\n",
      "194851       3.0          1116.0            1.0    1460.0    16581.0   1278.0\n",
      "839854       3.0          1126.0            1.0    1034.0   352604.0   1150.0\n",
      "452316       3.0          1120.0            1.0    1072.0  1585169.0   4767.0\n",
      "96311        3.0          1112.0            1.0    1412.0   324366.0   1220.0\n",
      "110290       3.0          1112.0            1.0    1606.0  4557386.0   4280.0\n",
      "187089       3.0          1116.0            1.0    1402.0  4167588.0   1238.0\n",
      "773597       3.0          1124.0            1.0    1066.0   402786.0   1125.0\n",
      "114850       3.0          1112.0            1.0    2103.0   339523.0  30575.0\n",
      "858502       3.0          1126.0            1.0    1213.0  1586252.0   1250.0\n",
      "492218       3.0          1120.0            1.0    1623.0   176409.0   3609.0\n",
      "427737       3.0          1119.0            1.0    1470.0  1268536.0  32819.0\n",
      "111759       3.0          1112.0            1.0    1608.0  1719768.0   3609.0\n",
      "88220        3.0          1112.0            1.0    1401.0  1579043.0  41938.0\n",
      "92080        3.0          1112.0            1.0    1407.0   330536.0    972.0\n",
      "830434       3.0          1126.0            1.0    1014.0  1043097.0   1182.0\n",
      "789436       3.0          1124.0            1.0    1214.0  4335456.0    972.0\n",
      "282203       3.0          1117.0            1.0    1450.0  1272568.0  35651.0\n",
      "152778       3.0          1113.0            1.0    2110.0  1244042.0  31310.0\n",
      "...          ...             ...            ...       ...        ...      ...\n",
      "6290         9.0         22560.0            1.0    1263.0  1815971.0   1687.0\n",
      "49359        9.0         23719.0            1.0    1160.0  4662738.0   1278.0\n",
      "50076        9.0         23719.0            1.0    1162.0  2334116.0  41938.0\n",
      "108971       9.0         24049.0            1.0    1204.0   599042.0   2233.0\n",
      "102354       9.0         23899.0            1.0    4503.0  4669766.0   1212.0\n",
      "116515       9.0         24049.0            1.0    4103.0  1172563.0   5000.0\n",
      "40629        9.0         23669.0            1.0    2123.0  1978422.0  32934.0\n",
      "168039       9.0         25759.0            1.0    1225.0  4483421.0  43200.0\n",
      "177718       9.0         25759.0            1.0    5503.0  2058383.0  45112.0\n",
      "17402        9.0         22560.0            1.0    2132.0  1888536.0  30531.0\n",
      "70202        9.0         23719.0            1.0    4405.0  2009286.0  43307.0\n",
      "97183        9.0         23899.0            1.0    2815.0  4572035.0   5337.0\n",
      "153604       9.0         25699.0            1.0    1205.0  2337869.0  37401.0\n",
      "121078       9.0         24539.0            1.0    1104.0   150132.0  43207.0\n",
      "139704       9.0         24669.0            1.0    1212.0  1315264.0  43196.0\n",
      "81464        9.0         23899.0            1.0    1226.0  2193803.0    972.0\n",
      "30064        9.0         23669.0            1.0    1115.0   250957.0  35651.0\n",
      "115242       9.0         24049.0            1.0    2904.0  1564516.0  30531.0\n",
      "41417        9.0         23669.0            1.0    2831.0   246772.0  30549.0\n",
      "150935       9.0         25699.0            1.0    1105.0   160661.0  43197.0\n",
      "50411        9.0         23719.0            1.0    1163.0  1116025.0   1216.0\n",
      "86511        9.0         23899.0            1.0    1234.0  1838655.0   1230.0\n",
      "31504        9.0         23669.0            1.0    1117.0  1989373.0   1232.0\n",
      "137566       9.0         24669.0            1.0    1207.0   120350.0  43200.0\n",
      "55541        9.0         23719.0            1.0    1276.0  2225575.0   2233.0\n",
      "109651       9.0         24049.0            1.0    1205.0   648349.0   1160.0\n",
      "105371       9.0         24049.0            1.0    1102.0   326425.0  34053.0\n",
      "20426        9.0         22560.0            1.0    2854.0  2442238.0   4245.0\n",
      "124517       9.0         24539.0            1.0    1203.0  4601950.0  34213.0\n",
      "140989       9.0         24669.0            1.0    1214.0  4461021.0  43203.0\n",
      "\n",
      "[150000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_samp_data(filename='train.csv', columns=[], load_pkl=1):\n",
    "    \"\"\" \n",
    "      Function returns a dataframe containing the training data sampled randomly. \n",
    "      The data is also stored in a pickle file for later processing.\n",
    "    \"\"\"\n",
    "    if load_pkl:\n",
    "        inputfile = open('train_samp_data.pkl', 'rb')\n",
    "        data = pickle.load(inputfile)\n",
    "        inputfile.close()\n",
    "        return data\n",
    "    \n",
    "    chunksize= 10 ** 6\n",
    "    datasize = 74180464 #datasize = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "    samplesize = 2*10 ** 3 # samples per chunk of data read from the file.\n",
    "    \n",
    "    data = pd.DataFrame([],columns=columns)\n",
    "    chunks = pd.read_csv(filename, iterator=True, chunksize=chunksize)\n",
    "    for chunk in chunks:\n",
    "        chunk.columns = columns\n",
    "        data = data.append(chunk.sample(samplesize)) \n",
    "    \n",
    "    # write data to a pickle file.\n",
    "    outputfile = open('train_samp_data.pkl','wb')\n",
    "    pickle.dump(data,outputfile)\n",
    "    outputfile.close()\n",
    "    \n",
    "    return data\n",
    " \n",
    "load_pkl = 1\n",
    "columns = ['week_num', 'sales_depot_id', 'sales_chan_id', 'route_id', 'client_id', 'prod_id', 'saleunit_curr_wk', 'saleamt_curr_wk', 'retunit_next_week', 'retamt_next_wk', 'y_pred_demand']\n",
    "tic = time.time()\n",
    "train_data_samp = load_samp_data('train.csv', columns, load_pkl)\n",
    "toc = time.time()\n",
    "print '*********'\n",
    "print 'Time to load: ', toc-tic, 'sec'\n",
    "print \n",
    "print train_data_samp.describe()\n",
    "print '*********'\n",
    "print train_data_samp[['week_num', 'sales_depot_id', 'sales_chan_id', 'route_id', 'client_id', 'prod_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary analysis \n",
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Time: 0.0148620605469 RMSLE (LinearRegression): 0.938368243688\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train = train_data_samp[['week_num', 'sales_depot_id', 'sales_chan_id', 'route_id', 'client_id', 'prod_id']].values\n",
    "labels_train = train_data_samp[['y_pred_demand']].values\n",
    "\n",
    "# Split the data samples into train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train, labels_train, test_size=0.33, random_state=42)\n",
    "\n",
    "# Linear regression\n",
    "tic = time.time()\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "pred[pred<0] = 0\n",
    "tac = time.time()\n",
    "print '----------'\n",
    "print 'Time:', tac-tic, 'RMSLE (LinearRegression):', rmsle(pred, y_test)\n",
    "print '----------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report ********\n",
      "Accuracy : 0.7968\n",
      "\n",
      "Model Report ********\n",
      "\n",
      "RandomizedSearchCV took 150.64 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.242 (std: 0.003)\n",
      "Parameters: {'max_features': 5, 'max_depth': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.241 (std: 0.003)\n",
      "Parameters: {'max_features': 6, 'max_depth': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.241 (std: 0.004)\n",
      "Parameters: {'max_features': 6, 'max_depth': 10}\n",
      "\n",
      "0.241613333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from operator import itemgetter\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [10],\n",
    "              \"max_features\": sp_randint(4, 7),\n",
    "              }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, n_jobs=4, cv=5)\n",
    "start = time.time()\n",
    "random_search.fit(features_train, np.ravel(labels_train))\n",
    "predict = random_search.predict(features_train)\n",
    "print '\\nModel Report ********'\n",
    "print \"Accuracy : %.4g\" % rmsle(np.ravel(labels_train), predict)\n",
    "print '\\nModel Report ********'\n",
    "print\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)\n",
    "print random_search.best_score_ \n",
    "print random_search.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff05b491290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEGCAYAAACToKXdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff05b491b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp = pd.Series(random_search.best_estimator_.feature_importances_).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, Xtrain, ytrain, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(Xtrain, label=ytrain)\n",
    "        print alg.get_params()['n_estimators']\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round = alg.get_params()['n_estimators'], early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        alg.fit(Xtrain, ytrain, eval_metric='auc')\n",
    "        predict = alg.predict(Xtrain)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9a73aa1321fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m  seed=27)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-49e4a6d7861e>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(alg, Xtrain, ytrain, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mcvresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m    440\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                               verbose_eval=verbose)\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=100,\n",
    " max_depth=15,\n",
    " min_child_weight=4,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'reg:linear',\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "predict = modelfit(xgb1, features_train, np.ravel(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print model report:\n",
    "print '\\nModel Report ********'\n",
    "print \"Accuracy : %.4g\" % rmsle(np.ravel(labels_train), predict)\n",
    "print '\\nModel Report ********'\n",
    "feat_imp = pd.Series(xgb1.booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=100, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27),  param_grid = param_test1, scoring='roc_auc', n_jobs=4,iid=False)\n",
    "gsearch1.fit(features_train,np.ravel(labels_train))\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   week_num  sales_depot_id  sales_chan_id  route_id  client_id  prod_id\n",
      "0        11            4037              1      2209    4639078    35305\n",
      "1        11            2237              1      1226    4705135     1238\n",
      "2        10            2045              1      2831    4549769    32940\n",
      "3        11            1227              1      4448    4717855    43066\n",
      "4        11            1219              1      1130     966351     1277\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.columns = ['id', 'week_num', 'sales_depot_id', 'sales_chan_id', 'route_id', 'client_id', 'prod_id']\n",
    "test_labels = pd.read_csv('sample_submission.csv')\n",
    "test_data = test_data.drop('id', 1)\n",
    "print test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.000306844711304\n",
      "100000   72.7710800171\n",
      "200000   145.477372885\n",
      "300000   218.045004845\n",
      "400000   290.581101894\n",
      "500000   363.356217861\n",
      "600000   436.15059185\n",
      "700000   509.013458014\n",
      "800000   581.852082014\n",
      "900000   654.530701876\n",
      "1000000   727.205648899\n",
      "1100000   800.080030918\n",
      "1200000   872.742459059\n",
      "1300000   945.787395\n",
      "1400000   1018.40329695\n",
      "1500000   1090.79495907\n",
      "1600000   1163.17800498\n",
      "1700000   1235.77449584\n",
      "1800000   1308.24206305\n"
     ]
    }
   ],
   "source": [
    "Xtest = test_data[['week_num', 'sales_depot_id', 'sales_chan_id', 'route_id', 'client_id', 'prod_id']].values\n",
    "y_pred = []\n",
    "tic = time.time()\n",
    "for ipred in xrange(len(Xtest)):\n",
    "    if ipred%10e4 == 0:\n",
    "        print ipred, ' ', time.time()-tic\n",
    "    y_pred.append(max(0, random_search.predict(Xtest[ipred,:])[0]))\n",
    "sub_dict = {'Demanda_uni_equil': np.ravel(y_pred)}\n",
    "sub_df = pd.DataFrame(sub_dict)\n",
    "sub_df.to_csv('sample_submission.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
